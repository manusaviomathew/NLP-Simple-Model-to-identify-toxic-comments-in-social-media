{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Training Sets, Test Sets and Output of Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=pd.read_csv('train.csv')\n",
    "test_set=pd.read_csv('test.csv')\n",
    "sample=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0  ...        2006  rejected      0    0    0      0         0   \n",
       "1  ...        2006  rejected      0    0    0      0         0   \n",
       "2  ...        2006  rejected      0    0    0      0         0   \n",
       "3  ...        2006  rejected      0    0    0      0         0   \n",
       "4  ...        2006  rejected      0    0    0      1         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0              0.0                         0                         4  \n",
       "1              0.0                         0                         4  \n",
       "2              0.0                         0                         4  \n",
       "3              0.0                         0                         4  \n",
       "4              0.0                         4                        47  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>No it won't . That's just wishful thinking on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>Instead of wringing our hands and nibbling the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>how many of you commenters have garbage piled ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...\n",
       "1  7000001  I actually inspected the infrastructure on Gra...\n",
       "2  7000002  No it won't . That's just wishful thinking on ...\n",
       "3  7000003  Instead of wringing our hands and nibbling the...\n",
       "4  7000004  how many of you commenters have garbage piled ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  prediction\n",
       "0  7000000         0.0\n",
       "1  7000001         0.0\n",
       "2  7000002         0.0\n",
       "3  7000003         0.0\n",
       "4  7000004         0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting out target toxicity and Comments from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train_set[['target','comment_text']]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining test set comments with the target toxicity level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>No it won't . That's just wishful thinking on ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>Instead of wringing our hands and nibbling the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>how many of you commenters have garbage piled ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text  prediction\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...         0.0\n",
       "1  7000001  I actually inspected the infrastructure on Gra...         0.0\n",
       "2  7000002  No it won't . That's just wishful thinking on ...         0.0\n",
       "3  7000003  Instead of wringing our hands and nibbling the...         0.0\n",
       "4  7000004  how many of you commenters have garbage piled ...         0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=test_set.merge(sample, how='inner', on='id')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a subset of training set of 70000 samples uisng random sampling for training and testing as the actual data is 1.8million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1574830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The answer to lower housing cost is not regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1764703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>It doesn't matter what the truth is.\\n\\nHe HAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Perhaps you should listen to the words your de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9180</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>I do, to the worthy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>495434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I don't know about you, but I have two!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index    target                                       comment_text\n",
       "0  1574830  0.000000  The answer to lower housing cost is not regula...\n",
       "1  1764703  0.000000  It doesn't matter what the truth is.\\n\\nHe HAS...\n",
       "2   285049  0.000000  Perhaps you should listen to the words your de...\n",
       "3     9180  0.142857                               I do, to the worthy.\n",
       "4   495434  0.000000            I don't know about you, but I have two!"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample=train.sample(n=70000,replace=False,axis=0).reset_index()\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the target into toxic(toxicity>=0.5) and non-toxic(toxicity<0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(train_sample)):\n",
    "    if train_sample.iloc[i,1]>=0.5:\n",
    "        train_sample.iloc[i,1]=1\n",
    "    else:\n",
    "        train_sample.iloc[i,1]=0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuations from comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    '''a function for removing punctuation'''\n",
    "    import string\n",
    "    # replacing the punctuations with no space, \n",
    "    # which in effect deletes the punctuation marks \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # return the text stripped of punctuation marks\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1574830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer to lower housing cost is not regula...</td>\n",
       "      <td>The answer to lower housing cost is not regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1764703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>It doesn't matter what the truth is.\\n\\nHe HAS...</td>\n",
       "      <td>It doesnt matter what the truth is\\n\\nHe HAS t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Perhaps you should listen to the words your de...</td>\n",
       "      <td>Perhaps you should listen to the words your de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I do, to the worthy.</td>\n",
       "      <td>I do to the worthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>495434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I don't know about you, but I have two!</td>\n",
       "      <td>I dont know about you but I have two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1362914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>One sure wonders about the professionalism of ...</td>\n",
       "      <td>One sure wonders about the professionalism of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>605992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Probably?  The share price is $0.70 at the tim...</td>\n",
       "      <td>Probably  The share price is 070 at the time y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>499356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\" didn't take any government handouts.\"\\n\\nThe...</td>\n",
       "      <td>didnt take any government handouts\\n\\nThe Val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>888982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I found a site that identifies eleven (11) Sta...</td>\n",
       "      <td>I found a site that identifies eleven 11 State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>278966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>O my God, that's disgusting.</td>\n",
       "      <td>O my God thats disgusting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  target                                       comment_text  \\\n",
       "0  1574830     0.0  The answer to lower housing cost is not regula...   \n",
       "1  1764703     0.0  It doesn't matter what the truth is.\\n\\nHe HAS...   \n",
       "2   285049     0.0  Perhaps you should listen to the words your de...   \n",
       "3     9180     0.0                               I do, to the worthy.   \n",
       "4   495434     0.0            I don't know about you, but I have two!   \n",
       "5  1362914     0.0  One sure wonders about the professionalism of ...   \n",
       "6   605992     0.0  Probably?  The share price is $0.70 at the tim...   \n",
       "7   499356     0.0  \" didn't take any government handouts.\"\\n\\nThe...   \n",
       "8   888982     0.0  I found a site that identifies eleven (11) Sta...   \n",
       "9   278966     1.0                       O my God, that's disgusting.   \n",
       "\n",
       "                                                text  \n",
       "0  The answer to lower housing cost is not regula...  \n",
       "1  It doesnt matter what the truth is\\n\\nHe HAS t...  \n",
       "2  Perhaps you should listen to the words your de...  \n",
       "3                                 I do to the worthy  \n",
       "4               I dont know about you but I have two  \n",
       "5  One sure wonders about the professionalism of ...  \n",
       "6  Probably  The share price is 070 at the time y...  \n",
       "7   didnt take any government handouts\\n\\nThe Val...  \n",
       "8  I found a site that identifies eleven 11 State...  \n",
       "9                          O my God thats disgusting  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample['text'] = train_sample['comment_text'].apply(remove_punctuation)\n",
    "train_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying stemming-reducing the words to a root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stemming(text):    \n",
    "    '''a function which stems each word in the given text'''\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1574830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer to lower housing cost is not regula...</td>\n",
       "      <td>the answer to lower hous cost is not regul or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1764703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>It doesn't matter what the truth is.\\n\\nHe HAS...</td>\n",
       "      <td>it doesnt matter what the truth is he has to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Perhaps you should listen to the words your de...</td>\n",
       "      <td>perhap you should listen to the word your deme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I do, to the worthy.</td>\n",
       "      <td>i do to the worthi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>495434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I don't know about you, but I have two!</td>\n",
       "      <td>i dont know about you but i have two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1362914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>One sure wonders about the professionalism of ...</td>\n",
       "      <td>one sure wonder about the profession of the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>605992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Probably?  The share price is $0.70 at the tim...</td>\n",
       "      <td>probabl the share price is 070 at the time you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>499356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\" didn't take any government handouts.\"\\n\\nThe...</td>\n",
       "      <td>didnt take ani govern handout the valley would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>888982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I found a site that identifies eleven (11) Sta...</td>\n",
       "      <td>i found a site that identifi eleven 11 state w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>278966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>O my God, that's disgusting.</td>\n",
       "      <td>o my god that disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  target                                       comment_text  \\\n",
       "0  1574830     0.0  The answer to lower housing cost is not regula...   \n",
       "1  1764703     0.0  It doesn't matter what the truth is.\\n\\nHe HAS...   \n",
       "2   285049     0.0  Perhaps you should listen to the words your de...   \n",
       "3     9180     0.0                               I do, to the worthy.   \n",
       "4   495434     0.0            I don't know about you, but I have two!   \n",
       "5  1362914     0.0  One sure wonders about the professionalism of ...   \n",
       "6   605992     0.0  Probably?  The share price is $0.70 at the tim...   \n",
       "7   499356     0.0  \" didn't take any government handouts.\"\\n\\nThe...   \n",
       "8   888982     0.0  I found a site that identifies eleven (11) Sta...   \n",
       "9   278966     1.0                       O my God, that's disgusting.   \n",
       "\n",
       "                                                text  \n",
       "0  the answer to lower hous cost is not regul or ...  \n",
       "1  it doesnt matter what the truth is he has to b...  \n",
       "2  perhap you should listen to the word your deme...  \n",
       "3                                 i do to the worthi  \n",
       "4               i dont know about you but i have two  \n",
       "5  one sure wonder about the profession of the to...  \n",
       "6  probabl the share price is 070 at the time you...  \n",
       "7  didnt take ani govern handout the valley would...  \n",
       "8  i found a site that identifi eleven 11 state w...  \n",
       "9                              o my god that disgust  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample['text'] = train_sample['text'].apply(stemming)\n",
    "train_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    64381\n",
       "1.0     5619\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only 8% of the total comments are toxic. Clearly there exists a class Imbalance. Hence, using precision recall and F1 score would be an ideal evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     train_sample.text, train_sample.target, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using CountVectorizer to tokenise comments, to remove stopwords, to use the tokens with frequency of more than 3 and finally to use the combination words upto 3(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vect = CountVectorizer(min_df=3,stop_words='english',ngram_range=(1,3)).fit(X_train)\n",
    "X_train = vect.transform(X_train)\n",
    "X_test = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearchCV and pipeline to find the best hyperparameters for Random Forest and Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label='pos')\n",
    "\n",
    "estimators = [('model', XGBClassifier())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "{'model': [XGBClassifier(random_state=0)],\n",
    " 'model__n_estimators':[100,500,1000,2000],\n",
    "'model__learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5]},\n",
    "{'model': [RandomForestClassifier(random_state=0)],'model__n_estimators':[100,500,1000,2000]}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid,scoring='f1', cv=5)\n",
    "fitted_search = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best algorithm and best parameters based on higher F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('model', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.3,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=2000, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_search.score(X_test, y_test)\n",
    "fitted_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the results of XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758285714285714 0.9378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97     32272\n",
      "         1.0       0.66      0.42      0.51      2728\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     35000\n",
      "   macro avg       0.81      0.70      0.74     35000\n",
      "weighted avg       0.93      0.94      0.93     35000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.3,n_estimators=2000, random_state=0)\n",
    "model=clf.fit(X_train, y_train) \n",
    "training_accuracy=model.score(X_train, y_train)\n",
    "test_accuracy=model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(training_accuracy,test_accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on GridSearch CV, XGB yielded the best F1 score. Out of the total Toxic predictions made, 66% have been correct(Precision). Out of the actual toxic comments, 42% have been identified as toxic(Recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
